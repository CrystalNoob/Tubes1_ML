{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self,value,_children=(),_op=''):\n",
    "        # REMINDER HAPUS CAST KE INT, CAST HANYA UNTUK TESTING\n",
    "        self.value = int(value);\n",
    "        self._prev = set(_children);\n",
    "        self._op = _op;\n",
    "        self.grad = 0.0;\n",
    "\n",
    "    def __repr__(self):\n",
    "        stringVal = f\"{self.value}\";\n",
    "        return stringVal\n",
    "\n",
    "    def __add__(self,other):\n",
    "        return Neuron(self.value + other.value,(self,other),'+');\n",
    "\n",
    "    def __sub__(self,other):\n",
    "        return Neuron(self.value - other.value,(self,other),'-');\n",
    "\n",
    "    def __mul__(self,other):\n",
    "        return Neuron(self.value * other.value,(self,other),'*');\n",
    "\n",
    "    def __div__(self,other):\n",
    "        return Neuron(self.value / other.value,(self,other),'/');\n",
    "\n",
    "    def hello():\n",
    "        print(\"hello\")\n",
    "\n",
    "    #TODO: Fungsi dan autograd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN19:\n",
    "    def __init__(self,\n",
    "                 hidden_layer_count=1,\n",
    "                 input_neuron_count=1,\n",
    "                 output_neuron_count=1,\n",
    "                 ):\n",
    "        \n",
    "        self.hidden_layer_count             = hidden_layer_count;\n",
    "        self.input_neuron_count             = input_neuron_count;\n",
    "        self.output_neuron_count            = output_neuron_count;\n",
    "        self._weight_layer_count            = hidden_layer_count+1;\n",
    "        self.weight_layers                  = [Neuron(0) for _ in range(self._weight_layer_count)];\n",
    "        self.hidden_layers                  = [Neuron(0) for _ in range(hidden_layer_count)];\n",
    "        self._activated_hidden_layers       = [Neuron(0) for _ in range(hidden_layer_count)];\n",
    "        self._output_layer                  = [Neuron(0) for _ in range(output_neuron_count)];\n",
    "        self._neuron_layer_set              = False;\n",
    "        self._weight_layers_initialized     = False;\n",
    "        self.outputs                        = []\n",
    "\n",
    "    # Vectorize is not the most efficient solution (gw mager)\n",
    "    def neuronGenerator(self,generator, *args, **kwargs):\n",
    "        value = generator(*args, **kwargs)\n",
    "        return np.vectorize(Neuron)(value)\n",
    "    \n",
    "    def setHiddenLayerNeuronCount(self,*args):\n",
    "        if len(args)==0:\n",
    "            for i in range(self.hidden_layer_count):\n",
    "                self.hidden_layers[i] = self.neuronGenerator(np.zeros,(input())+1)\n",
    "                self.hidden_layers[i][0] = Neuron(1)\n",
    "            self._neuron_layer_set    = True\n",
    "        elif len(args)==1:\n",
    "            if len(args[0])!=self.hidden_layer_count:\n",
    "                raise ValueError(f\"Layer count mismatch: expected {self.hidden_layer_count} hidden layer, but {len(args[0])} were given\")\n",
    "            else:\n",
    "                for i in range(self.hidden_layer_count):\n",
    "                    self.hidden_layers[i] = self.neuronGenerator(np.zeros,args[0][i]+1)\n",
    "                    self.hidden_layers[i][0] = Neuron(1)\n",
    "                self._neuron_layer_set = True\n",
    "        else:\n",
    "            raise TypeError(f\"FFNN19.setHiddenLayerNeuronCount() takes exactly 1 positional arguments but {len(args)} were given\")\n",
    "\n",
    "    def zeroWeightInitialization(self):\n",
    "        if self._neuron_layer_set:\n",
    "            for i in range(self._weight_layer_count):\n",
    "                if i==0:\n",
    "                    self.weight_layers[i] = self.neuronGenerator(np.zeros,(self.input_neuron_count+1,len(self.hidden_layers[i])))\n",
    "                elif i==self._weight_layer_count-1:\n",
    "                    self.weight_layers[i] = self.neuronGenerator(np.zeros,(len(self.hidden_layers[i-1]),self.output_neuron_count))\n",
    "                else:\n",
    "                    self.weight_layers[i] = self.neuronGenerator(np.zeros,(len(self.hidden_layers[i-1]),len(self.hidden_layers[i])))\n",
    "            self._weight_layers_initialized     = True;\n",
    "        else:\n",
    "            raise ValueError(self._neuron_layer_set_message)\n",
    "\n",
    "    def uniformWeightDistribution(self,lower,upper,seed):\n",
    "        if self._neuron_layer_set:\n",
    "            rng = np.random.default_rng(seed)\n",
    "            for i in range(self._weight_layer_count):\n",
    "                if i==0:\n",
    "                    self.weight_layers[i] = self.neuronGenerator(rng.uniform,lower,upper,size=(self.input_neuron_count+1,len(self.hidden_layers[i])))\n",
    "                elif i==self._weight_layer_count-1:\n",
    "                    self.weight_layers[i] = self.neuronGenerator(rng.uniform,lower,upper,size=(len(self.hidden_layers[i-1]),self.output_neuron_count))\n",
    "                else:\n",
    "                    self.weight_layers[i] = self.neuronGenerator(rng.uniform,lower,upper,size=(len(self.hidden_layers[i-1]),len(self.hidden_layers[i])))\n",
    "                if i!=self._weight_layer_count-1:\n",
    "                    self.weight_layers[i][:,0] = Neuron(0)\n",
    "            self._weight_layers_initialized     = True;\n",
    "        else:\n",
    "            raise ValueError(f\"Neuron layer count not set, please set neuron layer count before weight initialization\")\n",
    "        \n",
    "    def normalWeightDistribution(self,mean,variance,seed):\n",
    "        if self._neuron_layer_set:\n",
    "            rng = np.random.default_rng(seed)\n",
    "            for i in range(self._weight_layer_count):\n",
    "                if i==0:\n",
    "                    self.weight_layers[i] = self.neuronGenerator(rng.normal,mean,variance,size=(self.input_neuron_count+1,len(self.hidden_layers[i])))\n",
    "                elif i==self._weight_layer_count-1:\n",
    "                    self.weight_layers[i] = self.neuronGenerator(rng.normal,mean,variance,size=(len(self.hidden_layers[i-1]),self.output_neuron_count))\n",
    "                else:\n",
    "                    self.weight_layers[i] = self.neuronGenerator(rng.normal,mean,variance,size=(len(self.hidden_layers[i-1]),len(self.hidden_layers[i])))\n",
    "                if i!=self._weight_layer_count-1:\n",
    "                    self.weight_layers[i][:,0] = Neuron(0)\n",
    "            self._weight_layers_initialized     = True;\n",
    "        else:\n",
    "            raise ValueError(f\"Neuron layer count not set, please set neuron layer count before weight initialization\")\n",
    "\n",
    "    # Single pass, masih bingung gmn caranya buat multiple\n",
    "    def _feedforward(self,input_data):\n",
    "        if self._weight_layers_initialized:\n",
    "            input_data.insert(0,1)\n",
    "            input_layer_neuron = self.neuronGenerator(np.array,object=input_data)\n",
    "            for i in range(self._weight_layer_count):\n",
    "                if i==0:\n",
    "                    self.hidden_layers[i] = np.sum(input_layer_neuron*self.weight_layers[i].T,axis=1)\n",
    "                    self.hidden_layers[i][0] = Neuron(1) \n",
    "                elif i==self._weight_layer_count-1:\n",
    "                    self._output_layer = np.sum(self.hidden_layers[i-1]*self.weight_layers[i].T,axis=1)\n",
    "                else:\n",
    "                    self.hidden_layers[i] = np.sum(self.hidden_layers[i-1]*self.weight_layers[i].T,axis=1)\n",
    "                    self.hidden_layers[i][0] = Neuron(1)\n",
    "            self.outputs.append(self._output_layer)\n",
    "        else:\n",
    "            raise ValueError(f\"Weight layers not initialized, please initialize weight layers before feedforward\")\n",
    "\n",
    "    # TODO, implementasi yg ini\n",
    "    def _backpropagation(self):\n",
    "        raise NotImplementedError(\"Belum diimplement\")\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        raise NotImplementedError(\"Belum diimplement\")\n",
    "    \n",
    "    def predict(self,X):\n",
    "        raise NotImplementedError(\"Belum diimplement\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInstance = FFNN19(\n",
    "    input_neuron_count=2,\n",
    "    hidden_layer_count=3,\n",
    "    output_neuron_count=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInstance.setHiddenLayerNeuronCount([4,5,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInstance.uniformWeightDistribution(1,4,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5 7 \n",
      "\n",
      "[[0 1 2 3 3]\n",
      " [0 3 3 1 2]\n",
      " [0 1 1 3 3]] \n",
      "\n",
      "[1 24 25 32 37] \n",
      "\n",
      "[[0 1 3 1 3 1]\n",
      " [0 3 3 3 3 3]\n",
      " [0 3 1 2 2 2]\n",
      " [0 1 1 1 3 1]\n",
      " [0 2 2 3 1 3]] \n",
      "\n",
      "[1 254 206 266 258 266] \n",
      "\n",
      "[[0 1 1 2 2 1 1 3 3]\n",
      " [0 1 3 1 1 1 3 2 2]\n",
      " [0 2 1 3 1 2 1 1 3]\n",
      " [0 3 2 2 3 2 2 2 2]\n",
      " [0 3 2 2 2 3 3 1 3]\n",
      " [0 1 3 3 2 1 3 3 1]] \n",
      "\n",
      "[1 2505 2815 2720 2308 2239 3073 2305 2701] \n",
      "\n",
      "[[1 3]\n",
      " [2 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [3 2]] \n",
      "\n",
      "[43524 38320]\n"
     ]
    }
   ],
   "source": [
    "modelInstance._feedforward([5,8])\n",
    "print(1,5,7,\"\\n\")\n",
    "\n",
    "print(modelInstance.weight_layers[0],\"\\n\")\n",
    "print(modelInstance.hidden_layers[0],\"\\n\")\n",
    "print(modelInstance.weight_layers[1],\"\\n\")\n",
    "print(modelInstance.hidden_layers[1],\"\\n\")\n",
    "print(modelInstance.weight_layers[2],\"\\n\")\n",
    "print(modelInstance.hidden_layers[2],\"\\n\")\n",
    "print(modelInstance.weight_layers[3],\"\\n\")\n",
    "print(modelInstance._output_layer)\n",
    "\n",
    "# print(modelInstance.weight_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([43524, 38320], dtype=object), array([43524, 38320], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "print(modelInstance.outputs)\n",
    "# print(modelInstance.outputs[1][0]._prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# n_input_neuron = 3 # jumlah neuron input \n",
    "# n_input_instance = 1 # jumlah instance input\n",
    "# n_hidden_layer = 2  # jumlah layer\n",
    "# n_output_neuron = 1\n",
    "# weight_layer_count = n_hidden_layer + 1\n",
    "\n",
    "\n",
    "# input_layer_neuron = valueGenerator(np.random.randint,1,5,size=(n_input_instance,n_input_neuron))\n",
    "# output_layer_neuron = valueGenerator(np.zeros,n_output_neuron)\n",
    "# hidden_layer_neuron = [Value(0) for i in range(n_hidden_layer)]\n",
    "# self.weight_layers = [Value(0) for i in range(weight_layer_count)]\n",
    "\n",
    "# for i in range(n_hidden_layer):\n",
    "#     hidden_layer_neuron[i] = np.zeros(int(input()))\n",
    "\n",
    "# for i in range(weight_layer_count):\n",
    "#     if i==0:\n",
    "#         # weight_layer_neuron[i] = np.random.randint(5,size=(n_input_neuron,len(hidden_layer_neuron[i])))\n",
    "#         self.weight_layers[i] = valueGenerator(np.random.randint,1,6,size=(n_input_neuron,len(hidden_layer_neuron[i])))\n",
    "#     elif i==weight_layer_count-1:\n",
    "#         self.weight_layers[i] = valueGenerator(np.random.randint,1,6,size=(len(hidden_layer_neuron[i-1]),n_output_neuron))\n",
    "#         # weight_layer_neuron[i] = np.random.randint(5,size=(len(hidden_layer_neuron[i-1]),n_output_neuron))\n",
    "#     else:\n",
    "#         self.weight_layers[i] = valueGenerator(np.random.randint,1,6,size=(len(hidden_layer_neuron[i-1]),len(hidden_layer_neuron[i])))\n",
    "#         # weight_layer_neuron[i] = np.random.randint(5,size=(len(hidden_layer_neuron[i-1]),len(hidden_layer_neuron[i])))\n",
    "\n",
    "# for i in range(weight_layer_count):\n",
    "#     if i==0:\n",
    "#         hidden_layer_neuron[i] = np.sum(input_layer_neuron[0]*self.weight_layers[i].T,axis=1) \n",
    "#     elif i==weight_layer_count-1:\n",
    "#         output_layer_neuron = np.sum(hidden_layer_neuron[i-1]*self.weight_layers[i].T,axis=1)\n",
    "#     else:\n",
    "#         hidden_layer_neuron[i] = np.sum(hidden_layer_neuron[i-1]*self.weight_layers[i].T,axis=1)\n",
    "\n",
    "# print(\"Input\")\n",
    "# print(input_layer_neuron)\n",
    "# print(\"Hidden Layer\")\n",
    "# print(hidden_layer_neuron)\n",
    "# print(\"Output\")\n",
    "# print(output_layer_neuron)\n",
    "# print(\"Weight\")\n",
    "# print(self.weight_layers)\n",
    "# print(\"\\n\")\n",
    "\n",
    "# print(type(self.weight_layers[0][0][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
